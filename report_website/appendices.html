<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Appendices - Companio</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="css/style.css">
</head>
<body>



  <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
    <div class="container">
        <a class="navbar-brand" href="index.html">Companio</a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav">
            <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav">
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="index.html" id="homeDropdown" role="button" data-bs-toggle="dropdown">Home</a>
                    <ul class="dropdown-menu">
                        <li><a class="dropdown-item" href="index.html#abstract">Abstract</a></li>
                        <li><a class="dropdown-item" href="index.html#Video">Video</a></li>
                            <li><a class="dropdown-item" href="index.html#Team Members">Team Members</a></li>
                            <li><a class="dropdown-item" href="index.html#Project Timeline">Project Timeline</a></li>
                    </ul>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="requirementsDropdown" role="button" data-bs-toggle="dropdown">Requirements</a>
                    <ul class="dropdown-menu">
                        <li><a class="dropdown-item" href="requirements.html#project-background">Project Background</a></li>
                        <li><a class="dropdown-item" href="requirements.html#client-requirements">Client Requirements</a></li>
                        <li><a class="dropdown-item" href="requirements.html#project-goal">Project Goal</a></li>
                        <li><a class="dropdown-item" href="requirements.html#user-interviews">User Interviews</a></li>
                        <li><a class="dropdown-item" href="requirements.html#personas">Personas</a></li>
                        <li><a class="dropdown-item" href="requirements.html#Use Cases">Use Cases</a></li>
                        <li><a class="dropdown-item" href="requirements.html#moscow">MoSCoW List</a></li>
                    </ul>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle " href="research.html" id="researchDropdown" role="button" data-bs-toggle="dropdown">Research</a>
                    <ul class="dropdown-menu">
                        <li><a class="dropdown-item" href="research.html#stakeholder-insights">Stakeholder Insights</a></li>
                        <li><a class="dropdown-item" href="research.html#Technology Research & Selection">Technology Research & Selection</a></li>
                        <li><a class="dropdown-item" href="research.html#RAG Algorithm">RAG Algorithm</a></li>
                        <li><a class="dropdown-item" href="research.html#Memory Games">Memory Games</a></li>
                        <li><a class="dropdown-item" href="research.html#Existing Solution Evaluation">Existing Solution Evaluation</a></li>
                        <li><a class="dropdown-item" href="research.html#Design Decisions Informed by Research">Design Decisions Informed by Research</a></li>
                    </ul>
                </li>
              
                <li class="nav-item"><a class="nav-link" href="ui-design.html">UI Design</a></li>


                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="system-design.html" id="designDropdown" role="button" data-bs-toggle="dropdown">System Design</a>
                    <ul class="dropdown-menu">
                      <li><a class="dropdown-item" href="system-design.html#System Architecture">System Architecture</a></li>
                      <li><a class="dropdown-item" href="system-design.html#Sequence Diagram">Sequence Diagram</a></li>
                      <li><a class="dropdown-item" href="system-design.html#Design Patterns">Design Patterns</a></li>
                      <li><a class="dropdown-item" href="system-design.html#Data Storage">Data Storage</a></li>
                    </ul>
                  </li>
                  


                <li class="nav-item"><a class="nav-link" href="implementation.html">Implementation</a></li>

                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="testing.html" id="testingDropdown" role="button" data-bs-toggle="dropdown">Testing</a>
                    <ul class="dropdown-menu">
                      <li><a class="dropdown-item" href="testing.html#testing-strategy">Testing Strategy</a></li>
                      <li><a class="dropdown-item" href="testing.html#unit-testing">Unit Testing</a></li>
                      <li><a class="dropdown-item" href="testing.html#integration-testing">Integration Testing</a></li>
                      <li><a class="dropdown-item" href="testing.html#uat">User Acceptance Testing</a></li>

                    </ul>
                  </li>



                  <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="evaluation.html" id="evaluationDropdown" role="button" data-bs-toggle="dropdown">
                      Evaluation
                    </a>
                    <ul class="dropdown-menu">
                      <li><a class="dropdown-item" href="evaluation.html#moscow-achievement">MoSCoW Achievement Table</a></li>
                      <li><a class="dropdown-item" href="evaluation.html#known-bugs">List of Known Bugs</a></li>
                      <li><a class="dropdown-item" href="evaluation.html#individual-contribution">Individual Contribution</a></li>
                      <li><a class="dropdown-item" href="evaluation.html#critical-evaluation">Critical Evaluation</a></li>
                      <li><a class="dropdown-item" href="evaluation.html#future-work">Future Work</a></li>
                    </ul>
                  </li>
                  
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="appendicesDropdown" role="button" data-bs-toggle="dropdown">Appendices</a>
                    <ul class="dropdown-menu">
                        <li><a class="dropdown-item" href="appendices.html#Monthly Videos">Monthly Videos</a></li>
                        <li><a class="dropdown-item" href="appendices.html#Bi-Weekly Blogs">Bi-Weekly Blogs</a></li>
                        <li><a class="dropdown-item" href="appendices.html#User Manual">User Manual</a></li>
                        <li><a class="dropdown-item" href="appendices.html#Development Manual">Development Manual</a></li>
                        <li><a class="dropdown-item" href="appendices.html#Privacy of Data">Privacy of Data</a></li>
                        
                    </ul>
                </li>
            </ul>
                <!-- Github Link -->
                <ul class="navbar-nav ms-auto">
                  <li class="nav-item">
                      <a class="nav-link" href="https://github.com/HJH-08/Group25" target="_blank" title="GitHub Repository">
                          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                              <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.7-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
                          </svg>
                      </a>
                  </li>
              </ul>
        </div>
    </div>
</nav>


    <!-- Page Content -->
    <div class="container mt-5 pt-5">
        <h1 class="text-center">Appendices</h1>

        <!-- Monthly videos -->
        <section id="monthly-videos" class="section bg-light py-5">
          <div class="container">
            <h2 class="text-center mb-5">Monthly Videos</h2>
            <div class="row">
              
              <!-- Video 1 -->
              <div class="card text-center">
                <div class="card-body">
                  <h5 class="card-title">December Video</h5>
                  <p class="card-text">Click below to watch on YouTube</p>
                  <a href="https://www.youtube.com/watch?v=DM8ZNDpYB-0" target="_blank" class="btn btn-primary">Watch Video</a>
                </div>
              </div>
        
              <!-- Video 2 -->
              <div class="card text-center">
                <div class="card-body">
                  <h5 class="card-title">Januray Video</h5>
                  <p class="card-text">Click below to watch on other platform</p>
                  <a href="https://liveuclac-my.sharepoint.com/:v:/g/personal/zcabszo_ucl_ac_uk/EV8G4x2M8qZApZ1bG71zaSUBg4jy5HQ0s_x8WlKJ1N9HEg?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=Hee9Ei" target="_blank" class="btn btn-primary">Watch Video</a>
                </div>
              </div>
        
              <!-- Video 3 -->
              <div class="card text-center">
                <div class="card-body">
                  <h5 class="card-title">February Video</h5>
                  <p class="card-text">Click below to watch on other platform</p>
                  <a href="https://drive.google.com/file/d/1gSY8hEvQMT2M7chzmTJVtaYVkFdITkrT/view?usp=sharing" target="_blank" class="btn btn-primary">Watch Video</a>
                </div>
              </div>
        
              <!-- Video 4 -->
              <div class="card text-center">
                <div class="card-body">
                  <h5 class="card-title">March Video</h5>
                  <p class="card-text">Click below to watch on other platform</p>
                  <a href="https://liveuclac-my.sharepoint.com/:v:/g/personal/zcabszo_ucl_ac_uk/ETvqIol-ALpNpH3pbU25ZlsB9S0AFbmMkKxXc3xEbVCkVw?nav=eyJyZWZlcnJhbEluZm8iOnsicmVmZXJyYWxBcHAiOiJPbmVEcml2ZUZvckJ1c2luZXNzIiwicmVmZXJyYWxBcHBQbGF0Zm9ybSI6IldlYiIsInJlZmVycmFsTW9kZSI6InZpZXciLCJyZWZlcnJhbFZpZXciOiJNeUZpbGVzTGlua0NvcHkifX0&e=OETg7y" target="_blank" class="btn btn-primary">Watch Video</a>
                </div>
              </div>
        
            </div>
          </div>
        </section>
        



        <!-- Bi-Weekly Blogs -->
        <section id="Bi-Weekly Blogs" class="section mt-5">
            <h2>Bi-Weekly Blogs</h2>
            <div class="accordion" id="biWeeklyAccordion">
          
              <div class="accordion-item">
                <h2 class="accordion-header" id="heading1">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse1">
                    Week 1 & 2 (Oct 22 ~ Nov 3 )       
                  </button>
                </h2>
                <div id="collapse1" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                  <div class="accordion-body">
                    <p>Our first couple of weeks were all about settling in, meeting each other properly, and understanding what this project was all about. We got our project brief and found out we'd be working with two partners: Avanade and the NHS. We also scheduled meetings with Fergus Kidd from Avanade and Dr. Andrew Tan from the NHS to get a clearer idea of what they had in mind.
                        </p>
                        
                    <p>
                        From Fergus, we learned that the goal was to build a chatbot with a simple, friendly user interface that could remember past conversations using long-term memory techniques like RAG (Retrieval-Augmented Generation). He also emphasized the importance of having avatars to make the chatbot more approachable, especially for elderly users. He kindly gave us access to Azure AI Foundry and the Microsoft Azure services marketplace so we could start testing and experimenting with the latest tech.
                    </p>

                    <p>
                        When we spoke to Dr. Tan, he helped us understand how this chatbot could be really useful in healthcare settings—like reminding older patients to take their medication. He made it clear that accuracy was critical, especially when it comes to health advice. The system shouldn't make things up or give false information, but he was hopeful about the positive role AI could play in this space.
                    </p>

                    <p>
                        By the end of these conversations, we had gathered a solid list of features and ideas that would shape our project. We also got our GitHub repository up and running to manage everything we'd be building. All in all, it was a great start and we were excited to dive in.
                    </p>
                
                  </div>
                </div>
              </div>


          
              
              <!-- Week 3 & 4 -->

              <div class="accordion-item">
                <h2 class="accordion-header" id="heading3">
                  <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse3">
                    Week 3 & 4 (Nov 4 ~ Nov 17):<strong>Shaping Ideas and Splitting Roles</strong> 

                  </button>
                </h2>
                <div id="collapse3" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                  <div class="accordion-body">
                    <p>This phase of the project was all about bringing structure to our ideas. We focused heavily on preparing our HCI (Human-Computer Interaction) report, which meant diving deeper into understanding our users and their needs.</p>
                    <p>Based on earlier discussions with our stakeholders, we summarised key user feedback and translated that into detailed personas, user scenarios, sketches, and a prototype.</p>
                    <p>Personas helped us visualise the different kinds of users we were designing for—like an elderly user who might be unfamiliar with technology but in need of companionship. Scenarios described how someone might use our chatbot day-to-day.</p>
                    <p>We also created low-fidelity sketches and an early prototype to explore how our interface might look and feel, and how the user would interact with it. This helped us think through the user journey and identify areas we could improve before building anything concrete.</p>
                   
                    <p>We met with Fergus online and walked him through what we had come up with. He gave us some valuable feedback and suggestions on making the interface even more intuitive, which we took on board as we refined our ideas.</p>
                    <p>Chris and Eleanor took charge of researching front-end technologies—looking at how we could make a chatbot interface that's not only functional but also visually engaging, complete with 3D avatars. Meanwhile, Nik and Jun Han explored the back end—digging into different chatbot APIs, RAG methods for long-term memory, and how to tie everything together smoothly.</p>
                    <p>We even started writing and pushing backend code to GitHub—our first technical milestone, and it felt great to finally bring the project to life!</p>
                  </div>
                </div>
              </div>


              <!-- Week 5 & 6 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading4">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse4">
                    Week 5 & 6 (Nov 18 ~ Dec 1): <strong>Off Development</strong> 
                </button>
                </h2>
                <div id="collapse4" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>This was the week everything started to come together—we officially began building the project!</p>
                    <p>For the front end, we decided to go with React. It's interactive, lightweight, and pairs well with Python-based backends through FastAPI. To keep things simple but functional, we represented our avatars using short 4-second looping videos or GIFs, giving the interface a lively and welcoming touch for users. We agreed that we could always upgrade this to more advanced 3D avatars later on once the core features were in place.</p>
                    <p>On the backend, we began experimenting with Microsoft's Semantic Kernel, which showed promise as a central AI "hub" to tie together all the different components of our chatbot. We explored how it could handle history context, manage long-term memory with RAG, and support prompt templating. Once we got the kernel running, we focused on integrating basic chatbot APIs and learning how to connect everything into a smooth pipeline.</p>
                    <p>For the online mode, we tested several APIs but eventually chose OpenAI's GPT API because it was fast, reliable, and consistently gave high-quality, natural responses. Its strong documentation also made integration easier, which helped speed up our progress.</p>
                    <p>For the offline mode, we chatted with Prof. Dean Mohamedally and our TAs, who recommended Microsoft Phi-3.5 and IBM Granite. These models were both lightweight and state-of-the-art—perfect for local inference without putting too much strain on memory or performance. We downloaded and ran them via Ollama, testing them directly on our machines. It was also the perfect opportunity to explore some of the useful AI tools provided in the Microsoft Azure Marketplace.</p>
                    <p>We met with Fergus again to update him on our progress and share the direction we were heading in. He gave us great feedback and input as always, and with his approval, we moved full speed ahead.</p>
                </div>
                </div>
            </div>
              
          

            <!-- Week 7 & 8 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading5">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse5">
                    Week 7 & 8 (Dec 2 ~ Dec 14): <strong>the Foundation</strong> 
                </button>
                </h2>
                <div id="collapse5" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>These two weeks were all about syncing up, refining our ideas, and setting the stage for the heart of our project. We came together to share progress, exchanged feedback with our TAs, and had another helpful catch-up with Fergus to get further input on our technical exploration so far.</p>
                    <p>The frontend team continued experimenting with React and focused on using state management to make the interface dynamic and responsive. With guidance from our TA Felipe, we explored how to create an intuitive and engaging user experience—something especially important given our elderly user base.</p>
                    <p>On the backend side, we explored the idea of fine-tuning our models to improve their tone—shifting responses to be more empathetic, warm, and companion-like, especially for healthcare-related queries. We even prepped the fine-tuned datasets and tried pushing them onto Ollama for local model training. Alongside that, our chatbot APIs were now fully integrated with the Semantic Kernel. Based on the user's mode (online or offline), the kernel dynamically selected the correct API and processed the request. It worked! While offline responses from Granite or Phi-3.5 didn't quite match the fluency of OpenAI's API, the results were still meaningful and good enough for a smooth conversation.</p>
                    <p>To add more personality, we engineered a system prompt template that would guide the chatbot to always respond in a warm and friendly manner—essentially giving it a consistent tone. With this base setup complete, we were excited to enter the next phase over the winter break: building long-term memory.</p>
                    <p>This was the most exciting part for us. Fergus suggested looking into Azure AI Search to power memory in the online mode, and we planned to explore Qdrant for a lightweight, hybrid RAG solution offline. New tools meant a learning curve—but we were curious and motivated to dive in. Slowly but surely, the pieces of our AI companion were coming to life.</p>
                    
                </div>
                </div>
            </div>


                        <!-- Week 9 & 10 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading6">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse6">
                    Week 9 & 10 (Jan 13 ~ Jan 26): <strong>Memory in Motion</strong>
                </button>
                </h2>
                <div id="collapse6" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>The new year kicked off with a fresh wave of energy as we jumped straight back into the project after winter break. The frontend team continued their work steadily—building, refining, and adding polish. Meanwhile, the backend team dove deep into making memory retention a reality.</p>
                    <p>For the online mode, we set up Azure AI Search, creating separate indexes for different users using their unique IDs. We spent time fine-tuning its configurations—trying different parameters to make sure the RAG (Retrieval-Augmented Generation) process worked effectively and reliably. User input was structured using a Pydantic BaseModel, then passed to the Azure service. We tested it rigorously to ensure that the chatbot was actually receiving useful, relevant context and could respond accordingly. Performance was promising, and we were excited about how it was shaping up.</p>
                    <p>On the offline side, we began integrating Qdrant, hosted via Docker. We explored hybrid RAG—a combination of vector search and keyword-based search. The results were solid, and after some tuning, it was ready to be plugged into the Semantic Kernel. Integration took a bit of work, especially since most of the Semantic Kernel's documentation was written in C# while our backend was in Python, but we navigated through it with some perseverance.</p>
                    <p>With memory shaping up nicely, we were ready to move on to another key feature: voice interaction. Under the guidance of Professor Dean, we started planning experiments with F5-TTS, a machine learning-driven text-to-speech model that's highly customizable—perfect for creating a more natural and companion-like voice experience.</p>
                    <p>On top of all this, we also worked on our elevator pitch. It was a fun challenge learning how to quickly and clearly explain the heart of our project. But honestly, with how passionate we were about what we were building, the excitement was easy to share. And we were just getting started—stay tuned for more!</p>
                </div>
                </div>
            </div>
            
            <!-- Week 11 & 12 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading7">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse7">
                    Week 11 & 12 (Jan 27 ~ Feb 9): <strong>Finding Our Voice</strong>
                </button>
                </h2>
                <div id="collapse7" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>While the frontend team continued their steady progress, the backend team focused on experimenting with voice—something that's essential to making our AI companion feel truly lifelike. We began testing F5-TTS, a cutting-edge text-to-speech model that let us upload a short audio clip and have the AI speak back in the same voice. The results were incredibly realistic—perfect for creating a comforting, familiar tone for elderly users.</p>
                    <p>But then came the reality check. As amazing as F5-TTS was, it was far too resource-intensive to be practical on most machines. So we pivoted and began exploring other options, running extensive tests on technologies like Coqui-TTS and Vosk. We compared their speeds, responsiveness, and even checked whether they supported male/female customization. It became clear that a balance between quality and accessibility would be key.</p>
                    <p>Meanwhile, our offline RAG system using Qdrant reached a stable point. The hybrid search mechanism (vector + keyword) was performing well and had been fully integrated with Semantic Kernel. It was returning useful, context-aware responses that gave us hope the offline version of our chatbot could be genuinely helpful.</p>
                    <p>At this point, we had an almost fully functional backend. We could run it via command line, select between different models, toggle between text or voice input/output, and receive intelligent replies. All we needed now was the frontend to bring it to life—to unify everything we'd built into a user-friendly experience. So we turned our attention toward bridging the two worlds: backend and frontend, to make Companio whole.</p>
                    
                </div>
                </div>
            </div>
            
            <!-- Week 13 & 14 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading8">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse8">
                    Week 13 & 14 (Feb 10 ~ Feb 23): <strong>The Final Integration Begins</strong>
                </button>
                </h2>
                <div id="collapse8" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>With great momentum from the previous weeks, we finally reached a milestone—our backend and frontend were coming together! We had successfully integrated Text-to-Speech (TTS) and Speech-to-Text (STT) into the Semantic Kernel, both for online and offline RAG modes. Everything—from embedding long-term memory to voice interaction—was now working behind the scenes.</p>
                    <p>The next big challenge was linking our Python backend with our JavaScript React frontend using FastAPI. After adjusting certain backend functions, such as converting audio into a format that browsers could properly play (rather than trying to stream it directly), we ran our first integration tests. It was pretty surreal—opening the React interface and watching all the APIs work in sync.</p>
                    <p>We conducted stress tests, tried every function repeatedly: uploading and retrieving from Azure AI Search, calling OpenAI, using Qdrant offline, toggling TTS/STT, and more—all while ensuring our unit tests still passed as features were added. And just like that, we had a fully functional chatbot with a working frontend interface. But something still didn't sit right.</p>
                    <p>The avatar—a static 4-second looping video of an AI-generated face—felt a little too robotic. It didn't capture the warmth or connection we wanted. So we brainstormed: what if we could personalise the chatbot further? Add memory games to boost cognitive engagement? Explore AR features for a more immersive feel? Automated healthcare reminders? These ideas flowed naturally.</p>
                    <p>We decided to look into using Three.js to render live 3D avatars for more interactivity and personality. The project wasn't done yet—far from it. There was still fine-tuning to be done, new ideas to test, and a report website to start building. But with the core in place, we were more excited than ever to take it to the next level.</p>
                   
                </div>
                </div>
            </div>
            
            <!-- Week 15 & 16 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading9">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse9">
                    Week 15 & 16 (Feb 24 ~ Mar 9): <strong>The Final Sprint Before the Showcase</strong>
                </button>
                </h2>
                <div id="collapse9" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>Exciting news kicked off our week—we found out that there would be a showcase where students and industry representatives would come to view our projects. The energy in the team instantly skyrocketed. This was our chance to show the world what we'd built, and we were determined to make it unforgettable.</p>
                    <p>Our newly revamped Three.js interface was looking amazing. The avatars—sourced from royalty-free libraries—were now animated, waving, and responding, making the experience feel more alive and interactive. The interface had become customisable, with users being able to change the background scenery, and we even added memory games, all fully coded in the frontend using JavaScript. These little touches helped turn our chatbot into a warm, engaging companion rather than just another digital tool.</p>
                    <p>That said, we knew there were still rough edges to polish. Some frontend elements were still out of proportion, and the page transitions and animations weren't quite as smooth as we wanted. We were also experimenting with adding a female avatar option and integrating female TTS voices for better personalisation.</p>
                    <p>Another important milestone was packaging the app so users wouldn't have to install each dependency manually. We planned to bundle the frontend using Electron and the backend using PyInstaller. However, this turned out to be trickier than expected—packaging the large React frontend took time, and we found that the backend had to be bundled into a folder, not a single file, due to the way Qdrant's local executable worked.</p>
                    <p>Meanwhile, the report website had its foundation set up but still needed lots of content and polishing. And though we'd been writing and running tests throughout the project, we doubled down on testing to ensure that everything still worked smoothly after recent refactors and additions.
                    </p>
                    <p>It was crunch time—everyone was giving it their all. But with a clear vision, strong teamwork, and lots of coffee, we were confident that we'd be ready to proudly present our work. The end was near, and we were ready to finish strong.</p>
                </div>
                </div>
            </div>
            
            <!-- Week 17 & 18 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading10">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse10">
                    Week 17 & 18 (Mar 10 ~ Mar 23): <strong>Sharing COMPANIO with the World</strong>
                </button>
                </h2>
                <div id="collapse10" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>These two weeks were incredibly special?we got the chance to showcase our project to clients and a group of 6th Form students as part of UCL CS AI For Good initiative. It was heartwarming to see how people from all walks of life were genuinely excited about our chatbot, COMPANIO. They offered us fresh ideas, like incorporating motion input for accessibility, and even sparked deeper conversations about AI ethics. Could AI ever replace the human touch? Should it? Where do we draw the line when it comes to mental health support? These reflections reminded us just how impactful this project could be—and the importance of building it with care.</p>
                    
                    <p>The showcase itself was a success—our demo ran smoothly, and people were impressed by the features we'd built. But the work didn't stop there. We finalised packaging the application: the frontend was bundled with Electron, and the backend was compiled as an executable folder, making it easier to install and run. The web application was also polished, with both the frontend and backend working seamlessly. We ran final rounds of testing, fixing any last-minute bugs that surfaced during the showcase.</p>
                    <p>We also met with Fergus to present our final product. Not only did we meet the original project requirements, but we had gone beyond them—adding text-to-speech, speech-to-text, chat history memory, and even cognitive memory games to support users. Fergus and the Avanade team were impressed and even offered to feature our work on their internal platform, which was a huge honour.</p>
                    <p>While one or two of us put the final touches on the code, the rest of the team focused on preparing the report website, editing project videos, and writing user documentation. We reflected on our journey—from brainstorming ideas and experimenting with tech, to finally seeing our AI companion come to life. It was incredibly rewarding to look back and see how far we'd come. COMPANIO wasn't just a chatbot anymore—it was a full-fledged, user-friendly, and intelligent companion ready to make a real difference.</p>
                </div>
                </div>
            </div>
            
            <!-- Week 19 -->
            <div class="accordion-item">
                <h2 class="accordion-header" id="heading11">
                <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse" data-bs-target="#collapse11">
                    Week 19 (Mar 24 ~ Mar 28): <strong>Saying Hello to Companio, and Goodbye (for now)</strong>
                </button>
                </h2>
                <div id="collapse11" class="accordion-collapse collapse" data-bs-parent="#biWeeklyAccordion">
                <div class="accordion-body">
                    <p>And just like that, we reached the final week of our COMPANIO journey. There were definitely mixed emotions—we were proud and happy to see how far our project had come, but also a little sad to say goodbye to the countless hours of brainstorming, experimenting, and building. Still, we couldn't be more proud of what we've created. Not only did we meet all the project requirements, we went above and beyond—adding rich features like long-term memory, text-to-speech, speech-to-text, memory games, and a customisable 3D avatar interface.</p>
                    <p>Most importantly, we built something meaningful. COMPANIO wasn't just a cool piece of tech—it was something that could genuinely help people, especially the elderly, by providing companionship, memory assistance, and comfort through friendly conversation. It was incredibly validating to see our work showcased to Avanade, school groups, and industry professionals, and to spark real conversations about how AI can be used in thoughtful and unconventional ways.</p>
                    <p>This week was all about the final polish—tying up loose ends, finalising our GitHub repository, updating the README and technical documentation, and completing our report website. We also took time to reflect, share our gratitude to Fergus, our TAs, and everyone who supported us with feedback and guidance throughout the journey. With thorough testing, packaging, and deployment-ready versions of both our online and offline modes, COMPANIO is now a complete, robust product—ready to be used, and ready to make a difference.</p>
                    <p>So with that, we say: hello, COMPANIO—and thank you to everyone who came along for the ride.</p>
                   
                </div>
                </div>
            </div>
  



            </div>
          </section>



        <!-- user_manual -->
        <section id="User Manual" class="section">
            <h2>User Manual</h2>
            <p>
                The <strong>Companio User Manual</strong> provides a comprehensive guide on how to use the system. It is designed to help users understand the full functionality of the AI companion, including installation, setup, interface navigation, and feature usage such as speech interaction and memory games.
              </p>
              <p>
                You can view the full manual using the link below:
              </p>
              <p>
                <a href="https://docs.google.com/document/d/1vuXO03M8sp1KvZPBZ0l76v3H4Q9kqK_mU05p5e_ytoA/edit?tab=t.0#heading=h.yzg2qm3kvo2" target="_blank">
                  Companio User Manual
                </a>
              </p>
        </section>

        <!-- development_manual -->
        <section id="Development Manual" class="section">
            <h2>Development Manual</h2>
            <p>
                The <strong>Companio Deployment Manual</strong> provides step-by-step guidelines for developers to deploy the system in both online and offline environments. It outlines the requirements, setup processes, environment variables, packaging instructions, and model configurations necessary for a smooth deployment experience.
              </p>
              <p>
                You can access the full deployment guide below:
              </p>
              <p>
                <a href="https://docs.google.com/document/d/1hv2t1lBdooDqmSWh7eosIdFKy-ktf08WEt1PcPqI5zk/edit?tab=t.0#heading=h.bdvkyqn2cb36" target="_blank">
                  Deployment Manual
                </a>
              </p>
        </section>



       
<section id="privacy" class="section mt-5">
  <h2>Privacy of Data</h2>

  <p>This section outlines the licensing and privacy considerations for the Companio AI desktop assistant, including the tools used and data protection measures in line with legal and ethical standards.</p>

  <!-- Component Licensing Overview -->
  <h3>Component Licensing Overview</h3>
  <div class="table-responsive">
    <table class="table table-bordered">
      <thead class="table-light">
        <tr>
          <th>Component Type</th>
          <th>Technology / Library</th>
          <th>License</th>
          <th>Notes</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>Frontend Framework</td><td>React, Three.js, React-Three-Fiber</td><td>MIT License</td><td>Used for UI and avatar rendering</td></tr>
        <tr><td>State Management</td><td>Zustand, React Context</td><td>MIT License</td><td>For managing local/global state</td></tr>
        <tr><td>TTS/STT (Online)</td><td>Azure Speech Services</td><td>Microsoft Commercial</td><td>Voice input/output in online mode</td></tr>
        <tr><td>TTS/STT (Offline)</td><td>TTS, Vosk</td><td>MIT / Apache-2.0</td><td>Offline voice interaction using local models</td></tr>
        <tr><td>Backend Framework</td><td>FastAPI, Python</td><td>MIT / PSF License</td><td>API and backend infrastructure</td></tr>
        <tr><td>Orchestration</td><td>Microsoft Semantic Kernel</td><td>MIT License</td><td>AI service routing and plugin integration</td></tr>
        <tr><td>LLMs</td><td>Azure OpenAI, IBM Granite, Phi-3.5</td><td>Microsoft / Proprietary</td><td>Language models for chat response</td></tr>
      </tbody>
    </table>
  </div>

  <!-- Third-Party Dependency License Breakdown -->
  <h3>Third-Party Dependency License Breakdown</h3>
  <div class="table-responsive">
    <table class="table table-bordered">
      <thead class="table-light">
        <tr>
          <th>Dependency / Tool</th>
          <th>License</th>
          <th>Usage Notes</th>
        </tr>
      </thead>
      <tbody>
        <tr><td>PyTorch</td><td>BSD-3-Clause</td><td>Used in speech synthesis and model inference</td></tr>
        <tr><td>FastEmbed</td><td>Apache-2.0</td><td>Used for offline hybrid RAG embeddings</td></tr>
        <tr><td>Qdrant</td><td>Apache-2.0</td><td>Vector DB for local memory</td></tr>
        <tr><td>Azure AI Search</td><td>Microsoft Commercial</td><td>Vector + keyword search in online mode</td></tr>
        <tr><td>Web Speech API</td><td>Browser-native / MPL-2.0</td><td>Fallback STT in offline browser</td></tr>
      </tbody>
    </table>
  </div>


  <style>
    #data-privacy ul li {
      margin-bottom: 1rem;
      line-height: 1.6;
    }
  </style>


  <!-- Data Privacy and Protection -->
  <section id="data-privacy" class="section mt-5">
  <h3> Data Privacy and Protection</h3>
  <ul>
    <li><strong>No Persistent Storage of PII by Default:</strong> While Companio does not intentionally collect personally identifiable information (PII), input from users may occasionally contain such data.</li>
    <li><strong>Online Mode Data Processing:</strong> When using online features (e.g., Azure OpenAI, Azure AI Search, Azure Speech Services), user inputs are processed through Microsoft Azure services. This may involve temporary transfers of data outside the UK/EU region depending on deployment.</li>
    <li><strong>Contractual Use with Avanade:</strong>  Use of Azure APIs is permitted under a valid enterprise developer contract with Avanade, authenticated via corporate credentials. This enables access to Microsoft's responsible AI infrastructure and encryption compliance.</li>
    <li><strong>Speech and Health Conversations:</strong> Some features (e.g., medication reminders, wellbeing check-ins) may involve user-initiated sharing of health-related inputs. No clinical diagnosis or treatment is inferred or stored.</li>
    <li><strong>Offline Privacy Option:</strong> Users can switch to offline mode (local LLM + TTS) at any time. In this mode, all processing occurs locally and avoids cloud-based transmission entirely.</li>
    <li><strong>Data Retention:</strong> Memory (used to recall past chats or reminders) is retained only during the session or until a user resets local data. No long-term storage is enforced by default.</li>
    <li><strong>Medical Disclaimer:</strong> <em>Companio is not a medical device and does not provide medical advice. It is intended for conversational companionship and general memory support only. Always consult a qualified healthcare professional for medical guidance.</em></li>
  </ul>
</section>


  <!-- Avatar Licensing -->
  <h3>Avatar and Animation Licensing</h3>
  <p>
    All external assests used by Companio have been carefully selected to ensure legal compliance with licensing terms. They are only used in ways permited by their respective providers.
  </p>
  <p>
    The avatar (male and female) models were obtained from CGTrader under a royalty-free license. These assets that we have chosen are provided free. We intehrated the avatars for better visualization and virtual assistants. No modification beyond animation integration has been applied. No redistribution of the original assets is performed. Attribution has been provided in accordance with the licensing requirements specified by the CGTrader authors.
  </p>
  <p>
    We adapted the avatar's movement using Mixamo, an Adobe service that offers motion capture animations. These assets are royalty-free and available for use by anyone with a valid Adobe account, in accordance with Adobe's terms of service. The use of Mixamo assets is permitted for both commercial and non-commercial applications as long as it is not distributed in isolation.
  </p>
  <p>
    All assets are used within the context of this project only. No resale, standalone distribution, or commercial exploitation of the models or animations occurs beyond the scope of the Companio assistant.
  </p>
</section>

        </section>
    </div>



    
      


    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
    <script src="js/scripts.js"></script>
<!-- Footer -->
<footer class="bg-dark text-white mt-5 py-4">
  <div class="container">
      <div class="row">
          <!-- Copyright information -->
          <div class="col-md-6">
              <h5 class="mb-2 text-white-50">Companio</h5>
              <p class="mb-2 text-white-50">© 2025. All rights reserved.</p>
              <p class="small">Developed by Group 25 - UCL Computer Science</p>
          </div>
          
          <!-- Footer navigation -->
          <div class="col-md-6">
              <ul class="nav justify-content-end">
                  <li class="nav-item">
                      <a class="nav-link text-white" href="https://github.com/HJH-08/Group25" target="_blank">
                          <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                              <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.7-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
                          </svg>
                          GitHub
                      </a>
                  </li>
              </ul>
          </div>
      </div>
  </div>
</footer>
</body>
</html>
